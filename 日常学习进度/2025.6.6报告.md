# 学习进度报告
不务正业可能是效果最好的放松方式？
## 阅读arxiv:2503.06342v1
### AI总结
* **提出了一种新的TPE（张量处理引擎）优化视角：** 传统的TPE优化主要集中在数据流或操作数重用策略上。本文则从MAC（乘法累加器）的位权重维度（bit-weight dimension）入手，为矩阵乘法提供了一个更细粒度的硬件优化视角。
* **引入了MAC操作的位权重维度分析：** 论文指出，MAC操作本身与矩阵乘法的结合，提供了更大的优化空间。通过分析MAC在位权重维度上的特性，可以发现潜在的优化机会。
* **提出了“位权重维度（bit-weight dimension）”的概念并将其应用于矩阵三重循环：** 论文以矩阵三重循环为例，引入了这一新的优化维度，旨在通过更精细的控制来提高TPE的性能。
* **开发了一种用于利用位权重维度的新型MAC阵列架构：** 针对位权重维度中的优化机会，论文设计并实现了一种新的MAC阵列架构，能够更好地利用这个新维度来提高性能。
* **提出了量化相关的优化策略：** 论文探讨了如何在量化场景下利用位权重维度进行优化，这对于当前深度学习中广泛使用的量化技术具有重要意义。
### 读后感
刚发现这篇论文的时候，曾经推荐过给您（谢老师）。但仔细阅读下来，我对这篇文章持一定的怀疑。这篇文章提到的方案实际上在集创赛的TPU项目中曾经被考虑过。对于文章的思路，其实可以更进一步地采用分治的思想（如蝶形运算）进一步“提高”计算的速度。那么为什么是曾经考虑过？首先，因为需要存储更多的中间积、更复杂的控制，所以面积会变大。其次，传统的压缩树和流水线形式的乘法器在处理32位数速度并不慢，甚至因为形式更加规整，会比拆分位有更好的效果。（而且集创赛赛题的输入输出格式很大程度限制了通过拆分提高并行度）。所以在当时，这一方案被弃用。不过由于当时过于仓促，没有考虑到稀疏和预测带来的效果，也有可能在设计或计算上存在一定的问题。（在知乎上有人声称复现了文章中的设计，在验证时取得了良好的效果）
## 了解伯克利大学的EE290课程
其实是找到了arXiv.1911.09925，然后发现这篇东西和伯克利大学的EE290课程相关。EE290做的是硬件（机器学习）加速器，与FPGA小组项目契合度较高，遂在此推荐。但是目前EE290对伯克利大学以外的人员是关闭的，要完整学习可能比较困难。现在我能找到相关的资源是[https://github.com/harrisonliew/cs252_ee290_project/tree/ee290]和[https://www.bilibili.com/video/BV1NE4m1d74U]，资源较旧。FPGA小组需要时，我会去观看学习（目前仅了解，还没细看）
### 阅读arXiv.1911.09925
#### AI总结
* [cite_start]**全栈式深度学习加速器生成器:** Gemmini 提供了一个开源、全栈的深度学习加速器设计基础设施，它能够系统地评估深度学习架构 [cite: 20][cite_start]。它不仅生成硬件加速器，还提供灵活的编程栈和带有共享资源的完整 SoC (片上系统)，从而能够捕获系统级效应 [cite: 4]。
* [cite_start]**灵活的硬件架构模板:** Gemmini 具有一个灵活的硬件模板和参数化设置，允许用户调整硬件设计选项，以平衡性能、效率和可扩展性 [cite: 13][cite_start]。它支持浮点和定点数据类型、多种数据流（可在设计时和运行时配置），以及向量和脉动阵列两种空间阵列架构，从而能够量化比较它们的效率和可扩展性差异 [cite: 40]。
* [cite_start]**多层级软件支持:** Gemmini 提供多层级软件流来支持不同的编程场景 [cite: 74][cite_start]。它包括一个“一键式”软件流，可以读取 ONNX 文件格式的 DNN 描述并生成相应的软件二进制文件 [cite: 75][cite_start]。同时，也可以通过 C/C++ API 进行低级别编程，并为常见的 DNN 核函数提供优化功能 [cite: 77]。
* [cite_start]**集成 SoC 环境和操作系统支持:** 与现有专注于独立加速器的 DNN 加速器生成器不同，Gemmini 提供了一个完整的解决方案，涵盖硬件和软件栈，以及与 RISC-V 生态系统兼容的完整 SoC 集成 [cite: 14][cite_start]。这使得加速器能够在包含操作系统的真实环境中运行，从而有助于发现“裸机”环境下无法暴露的错误和低效率问题 [cite: 99][cite_start], [cite: 100]。
* [cite_start]**对虚拟内存的硬件支持:** Gemmini 是第一个提供虚拟内存硬件支持的基础设施，无需特殊的驱动软件，大大简化了终端用户对加速器的编程 [cite: 47]。
* [cite_start]**协同设计能力:** Gemmini 实现了加速器、应用程序和系统的协同设计，为未来的深度学习 SoC 集成开辟了新的研究机会 [cite: 18][cite_start]。例如，设计者可以利用 Gemmini 优化深度学习加速器工作负载的虚拟地址转换机制，并平衡 DNN 中不同层类型的计算要求来划分内存资源 [cite: 19]。
#### 并不是读后感
这篇文章所在的分区是CCF A区，研究也确实足够优秀（至少我能感受到）。这里没有很详细地写出详细的实现（详见[https://github.com/ucb-bar/gemmini]）。源码是scala也看不懂，如果没有这方面的需要等话，可能放在python以后再学。
## 对集创赛的反思
这次集创赛中我们的项目开发是及其混乱的。我认识到了“编程作业”、“玩具项目”、“项目”的区别（比赛项目可以看作玩具项目，而arXiv.1911.09925中的Gemmini可以看作项目）。项目越大，其中模块越多、依赖关系也越复杂，模块开发过程中进度的差异和测试中暴露出的问题越大。就拿集创赛为例，我们没有很好地规划各模块（尤其是接口），生成的代码和手写的代码混用，没对各模块进行独立的测试，开发途中频繁更改方案。这些都导致了这次的失败。对于类似的项目（3-7人，工期约3月），应该采取类似敏捷开发的思想，在前期确定模块和接口，并通过迭代的方式更改方案。
## 阅读DOI:10.1109/ISCA59077.2024.00069
### AI总结
* **提出张量收缩处理器 (TCP) 架构 (Novel Tensor Contraction Processor Architecture):** TCP 提出了一种与传统依赖固定大小矩阵乘法的架构不同的范式。它旨在利用张量收缩固有的丰富并行性和数据局部性，从而提高 AI 工作负载的效率和性能。
* **粗粒度处理单元 (Coarse-Grained Processing Elements - PEs):** TCP 由粗粒度 PE 组成，以简化软件开发。
* **灵活的 PE 设计 (Flexible PE Design):** 为了高效处理具有不同张量形状的操作，PE 被设计得足够灵活，能够适应各种张量收缩模式，包括点积、矩阵向量乘法、矩阵矩阵乘法和张量张量乘法。
* **统一的张量收缩指令 (Unified Tensor Contraction Instruction):** TCP 引入了一个统一的张量收缩指令，通过单一指令集来执行所有张量收缩操作，从而简化了编程模型。
* **独特的片上网络 (Unique On-Chip Network - OCN):** 论文中可能提到了创新的 OCN 设计，以支持高效的张量数据流和通信。 (需要进一步阅读论文以确认细节)
* **多层次存储层次结构 (Multi-Level Memory Hierarchy):** 论文中可能提到了针对张量工作负载优化的存储层次结构，以最大化数据重用和带宽利用率。 (需要进一步阅读论文以确认细节)
### 不是读后感
A区文章，还没读完。我还有arXiv:2412.09709v1没读完，这两篇东西可能对FPGA项目有较大参考意义。