# 学习进度报告
## 对FPGA兴趣小组的疑惑
听说兴趣小组是没申请到创谷的实验室，非常遗憾。我觉得这反映了团队的一些问题。
 * 目前来说，团队没有明确当前项目的方向，包括更为具体的课题、技术路线和项目开发上的规划。
 * 缺少交流。
 * 缺少项目的开发模式。
最近两周稍微看了点与项目、团队管理方面的内容。虽然感觉小组有诸多不足，但因我认知有限，也想不出很好的解决办法。
## 给暑假初步定个待完成事项
尚未排列重要性和完成时间限制
 * 通过一生一芯的预学习考核，并尝试完成一个阶段
 * 复习线性代数，完成一本教科书上至少一半的习题
 * 学习抽象代数，尤其是掌握和群相关的知识
 * 学习图论，并尝试理解GNN
 * 复习Verilog和systemverilog，将集创赛未完成的部分完成
 * 学习python，并练习数学建模
 * 完成LoRI相关的继续研究
 * （可能）学习scala（chisel）
## 阅读DOI:10.1109/ISCA59077.2024.00069
AI摘要见上期
### 读后感
使用了分块的方式对张量进行计算，比tensor core(nvidia)、tpu(谷歌)这种固定大小的张量核更为灵活。感觉上，像是一个只支持SIMD的，规模很大的CPU。不过更详细和具体的实现方式可能需要阅读相关的库（如果是公开的）。
这篇文章的产物是Furiosa AI芯片。相较于tpu，此芯片天然地支持softmax、ReLU等对向量（矩阵或张量）的更多处理，显得更为通用。此芯片的设计对GNN的FPGA加速器设计是有很大启发意义的。
## 阅读arXiv:2412.09709v1
### AI摘要
**创新点：**
* **对角线输入和置换权重驻留（DiP）数据流：** 论文提出了一种新颖的可扩展脉动阵列架构，其核心是DiP数据流，用于加速矩阵乘法。
* **消除同步FIFO：** DiP架构消除了现有最先进的权重驻留脉动阵列所需的输入和输出同步FIFO（先进先出缓冲区）。
* **提高PE（处理单元）利用率和吞吐量：** 通过消除FIFO，DiP架构不仅节省了面积、功耗和能源，还最大限度地提高了计算资源（PE）的利用率，从而使吞吐量比现有权重驻留方案提高了高达50%。
* **支持通用矩阵乘法：** DiP架构能够执行各种矩阵乘法模式，包括向量-矩阵乘法（VMM）、矩阵-向量乘法（MVM）和矩阵-矩阵乘法（MMM），这使其适用于Transformer模型中的各种操作。
* **灵活性和可配置性：** DiP架构具有高度的灵活性和可配置性，可以适应不同的计算需求和模型尺寸。
**创新点所受的启发或数学基础：**

* **Transformer模型的需求：** 论文指出，Transformer模型在NLP应用中表现出色，但其数据密集型特性对现有计算架构提出了显著的性能要求。这启发了研究人员寻找更高效的加速方法。
* **脉动阵列的优势与挑战：** 脉动阵列因其数据重用带来的能效优势而被商业AI计算平台（如Google TPUs）采用。然而，现有的脉动阵列需要FIFO进行输入和输出同步，这会带来吞吐量和能效损失。这促使研究人员思考如何消除或改进这一瓶颈。
* **解决现有脉动阵列的同步开销：** 论文明确指出，现有的权重驻留脉动阵列在处理对角线数据流时面临同步挑战，需要在每个时钟周期存储对角线元素。DiP通过设计新颖的数据流来解决这一问题。
* **利用稀疏性进行优化（潜在的数学基础）：** 虽然论文没有明确指出具体的数学定理，但其对数据流的优化，特别是通过对角线输入和置换权重驻留来提高PE利用率，隐含了对数据访问模式和计算效率的深刻理解。这可能涉及到对矩阵乘法并行化和数据依赖图的深入分析。
**局限性或未来可能的研究方向：**

* **特定应用场景的优化：** 论文主要关注Transformer模型中的矩阵乘法加速。未来研究可以探索DiP架构在其他AI模型或计算密集型应用中的适用性及其优化潜力。
* **硬件实现和物理设计：** 论文提出了架构层面的创新。未来的工作可以深入探讨DiP架构在实际ASIC设计中的物理实现细节、布局布线、时序收敛等问题，以验证其在真实硬件中的性能和功耗表现。
* **内存层次结构和数据搬运：** 尽管DiP优化了片上数据流，但从片外内存到片上缓冲区的原始数据传输仍然是能耗和性能瓶颈。未来的研究可以探索更优化的内存层次结构、数据预取策略或片上数据压缩技术，以进一步提高整体系统的能效。
* **异构计算环境：** DiP架构主要针对ASIC设计。未来的研究可以考虑如何在FPGA或其他可重构计算平台上高效实现DiP，或将其与通用处理器（CPU/GPU）结合，构建异构计算系统。
* **支持更多数据类型和精度：** 论文中可能未详细说明对不同数据类型（如浮点数、定点数、量化数据）和精度的支持。未来的研究可以探索DiP架构如何高效支持这些不同类型的数据，以适应更广泛的AI应用需求。
* **错误鲁棒性和容错性：** 随着计算规模的增大，硬件错误变得更加普遍。未来的研究可以探索DiP架构中如何集成错误检测、纠正和容错机制。
* **软件栈和编程模型：** 为了充分发挥DiP架构的优势，需要相应的编译工具链和编程模型来将高级语言描述的AI模型映射到DiP硬件上。这方面的研究可以简化开发并提高生产力。
* **更复杂的拓扑结构：** 论文关注的是二维脉动阵列。未来的研究可以探索DiP数据流是否可以应用于更高维度或更复杂的互连拓扑结构中，以支持更大规模的矩阵运算。
### 读后感
在集创赛项目中，由于题目中的输入矩阵总是变化的，我们使用了输出静止的方式。然而实际的应用场景远比矩阵的乘加运算更加复杂。像在不考虑反向传播仅推理的情况下，固定权重是不错的选择。而本文提到的DiP结构固定了行，更适合数据串行地从一个模块传向另一个模块，消除了同步FIFO，减小了面积和功耗，同时也减小了缓冲区带来的延迟。
