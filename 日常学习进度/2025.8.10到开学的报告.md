# 近况
有3个星期没写报告了。中间参杂了一些原因，但是大抵能归结为借口。
准备了下数模，尝试做了两道题。一题在统计数据时出现莫名的数据缺失（大概是几十列原本大概是几十到几百的数据变成了不大于20的数据），debug也没de出个所以然，感觉是溢出（因为读取的表格有880万行，也有可能是文字匹配时当成无效数据（数据可能带了空格，我又没做正则匹配）。然后有点不了了之。另一题就尝试使用了遗传算法。可能是约束太多的缘故，在一开始并没有收敛，大概浪费了两天时间在处理。最后把一些约束改成惩罚，同时使用蚁群算法给出初始解，就暂时地可以运行了。但是单次运行居然需要7小时之久，一看一个函数里面显式地叠了5个for。因为时间不多便让AI优化顺便并行化。在扩大参数后，大概运行3小时。因为我们的论文手忙导致退赛，不得不参与写两篇论文。当初texlive没配置好，总是缺宏包导致无法编译模板，不得不用了word。word也是问题多多，格式错乱、插入图片错乱、插入公式错乱、脚注格式。。。在另一名同学的帮助下，我们找到了新队友（在第二篇论文开始时）。在上交论文后，指导老师询问我们是不是共同独立完成的（总感觉话里有话，大概是说这篇论文看上去像三个人各写各的，所谓“共同”而“独立”）。总的下来，大概消耗了两个星期吧。
服务器已经就绪。可运行gpt-oss-20b、完整的texlive、openfoam，可谓性能强劲。同时视频输出、远程也是能用的。待9月7日数模结束后，就可以搬至机房。
一生一芯的面试还没去申请，大概是因为8月初感冒歇了会，然后后面又在搞数模导致的（都是借口）。
## 对DeepSeek-V3.1的一些猜测
UE8M0的fp8格式非常奇怪。没有符号位意味着会丢失很多信息。在这点上，我猜测是有映射或者另外的位处理机制。此格式下的乘看上去就和int8的加一样，
## 阅读论文 Optimizing CNN Computation Using RISC-V Custom Instruction Sets for Edge Platforms
### AI总结
#### 创新点 (Innovations)
* **定制指令集：** 论文提出并实现了一套包含七个RISC-V SIMD（单指令多数据）定制指令集，用于显著优化卷积神经网络（CNN）的推断计算，包括卷积、激活和池化操作 。
* **指令融合与数据复用：** 这些定制指令可以在一个加速模块内以批处理模式（也称为指令融合）执行，从而避免了重复的内存读写访问，并减少了相关的延迟和能耗 。例如，`CONV23`指令实现了一种数据复用机制，可以避免在连续卷积操作中重复加载冗余数据 。
* **协处理器设计：** 定制指令被嵌入一个协处理器（即加速模块）中，可以直接通过RISC-V CPU调用 。这种架构与许多使用PE脉动阵列（PE systolic array）的其他CNN加速器不同 。
* **低功耗与小硬件占用：** 加速模块专门为低功耗操作进行了优化，与其他作品相比，其硬件占用面积更小 。
* **网络模型优化：** 论文还通过将卷积层和池化层融合为一个“conv-pool”层来优化LeNet-5、VGG16和ResNet18等网络模型 。

#### 数学基础或启发 (Mathematical Foundations or Inspirations)
* **Winograd算法：** 论文的核心是采用Winograd算法来加速卷积操作 。通过该算法，`F(2x2, 3x3)`卷积的乘法次数可以从36次减少到16次，执行时间从140个时钟周期减少到21个 。该算法的优势在于，它减少了乘法运算的次数，而乘法运算通常比加法运算需要更多的资源和延迟 。
* **RISC-V架构：** 整个工作基于开源的RISC-V架构，并使用了RISCY作为基础处理器 。RISC-V的开放式指令集架构（ISA）允许灵活地定制和添加指令，这是实现本文所提方案的基础 。

#### 不足或后续研究方向 (Shortcomings or Future Research Directions)
根据提供的文档内容，未找到明确的“不足”或“后续研究方向”部分 。但是，可以推断出以下几点：
* **仅关注推理：** 论文主要关注CNN的推理计算加速 ，并未讨论如何将这些定制指令集扩展到支持CNN的训练过程。
* **缺少结论：** 论文内容缺少第V和第VI节，即关于硬件资源开销、延迟和功耗的详细讨论以及结论部分 。这部分内容本应包含对该研究的全面评估，但在此文件中缺失。
* **专注于特定核尺寸：** 论文的加速方法主要针对`3x3`的卷积核进行优化 。尽管这种尺寸在CNN中很常见，但并未讨论该方法对其他尺寸卷积核的适用性或性能表现。
### 读后感
了解到除了FFT/NTT以外的卷积算法lm2col和Winograd。在使用winograd算法时，将矩阵乘法展成向量乘法，确实可以更好地适应已有的向量操作。

## 阅读论文 IMPACT: Importance-Informed Prefetching and Caching for I/O-Bound DNN Training
### AI总结 
#### 创新点 (Innovations)
* **I/O导向的重要性采样 (I/O-oriented importance sampling, IIS)：** 论文首次提出了I/O导向的重要性采样（IIS）思想，并将其应用于预取和缓存系统ImPACT中，旨在通过减少从存储或缓存中获取的数据量来加速I/O密集型DNN训练 。
* **混合重要性评估方法：** 针对在预取前样本重要性未知且会随时间变化的问题，论文提出了一种混合重要性评估方法。该方法基于一个观察结果：大部分训练样本的重要性排名是稳定的，而只有一小部分样本会发生显著波动 。这种方法可以在引入最小I/O开销的同时准确评估样本的重要性 。
* **双分区缓存架构：** ImPACT引入了一个重要性感知的缓存层，将其划分为H-cache（存储高重要性样本）和L-cache（存储低重要性样本）两个区域 。H-cache中的数据管理不依赖于传统的近因或频率策略，而是根据样本的重要性值进行管理 。
* **动态打包技术：** 为了减少对低重要性样本（L-samples）进行随机I/O访问所带来的性能瓶颈，ImPACT使用了动态打包技术，将L-samples分批加载到L-cache中 。
* **H-heap 和 Shadow Heap 缓存管理：** 论文设计了一种基于小顶堆（H-heap）的缓存管理机制来管理H-cache，当H-cache满时，会根据重要性值决定是否驱逐数据项 。为了高效地在重要性值变化时重新填充缓存，ImPACT还管理了一个“影子堆”来记录H-heap的变化 。

#### 数学基础或启发 (Mathematical Foundations or Inspirations)
* **重要性采样 (Importance Sampling, IS)：** 论文的核心思想源于重要性采样，这是一种通过跳过部分数据项的计算来加速DNN训练，同时保持模型准确性的方法 。现有的方法大多是计算导向的重要性采样（CIS），只关注减少GPU计算，而ImPACT则将其思想扩展到I/O层面 。
* **SGD算法：** 样本重要性值会随着训练过程中SGD算法对模型参数（如权重）的迭代更新而改变 。ImPACT的设计考虑了这一动态变化，并提出了相应的缓存管理策略 。
* **替代性 (Substitutability)：** 论文借鉴了Quiver [9]等系统的思想，在L-cache中应用了替代性技术。当需要访问的L-samples不在L-cache中时，可以用缓存中已有的L-samples进行替代，从而减少随机I/O的数量并保持较高的训练精度 。

#### 不足或后续研究方向 (Shortcomings or Future Research Directions)
论文中没有明确的“不足”或“后续研究方向”部分。但从其内容和对相关工作的对比中可以推断：
* **重点在I/O瓶颈：** 该工作主要关注I/O密集型DNN训练，对于计算密集型任务的性能提升可能有限。
* **参数调优：** 论文提到设置 S 集（需要重新评估重要性值的样本集合）的大小时，通过实验经验性地选择了25%作为默认值 。这表明该参数可能需要根据具体模型和数据集进行调优，未来可以研究更自动化的参数选择方法。
* **分布式训练：** 论文主要关注单节点架构 ，ImPACT在分布式训练环境下的扩展性和性能还有待进一步研究。
### 读后感
感觉上是对一种机制上的探讨，而不是创新机制。相比起通过计算导向的重要性采样，本文采用的方法有一定启发性，效果更好。

## 阅读论文
### AI总结
#### 创新点 (Innovations)
* **节点复用方法 (Node-reuse approach)：** 论文提出了一种节点复用方法，用迭代代替递归来执行MBE算法。该方法通过在固定的内存区域内重用单个节点缓存（node_buf）来显著减少GPU内存使用，从而避免了昂贵的动态内存分配。
* **基于位图的集合交集 (Bitmap-based set intersection)：** 该方法在节点包含少量顶点时使用位图来存储邻接关系，并通过位运算来加速集合交集操作。这有效地最小化了GPU中的线程发散（thread divergence）问题。
* **负载感知任务调度框架 (Load-aware task scheduling framework)：** 为了解决GPU上的负载不平衡问题，GMBE+设计了一个负载感知的任务调度框架，该框架使用两级队列来平衡GPU warp内线程之间的工作负载。此外，该框架还提出了一种基于“交集路径（intersect-path）”的集合并集方法来辅助负载均衡。
* **局部邻域大小的剪枝方法 (Pruning approach using local neighborhood size)：** GMBE+通过在节点缓存中维护候选顶点的局部邻域大小，实现了GPU友好的剪枝策略。该方法可以有效地移除那些在遍历其子节点后局部邻域大小不变的无用候选节点，从而减少枚举空间。

#### 数学基础或启发 (Mathematical Foundations or Inspirations)
* **最大二分团枚举 (Maximal Biclique Enumeration, MBE)：** 该研究是基于解决二分图中的最大二分团枚举问题的。这项工作在数据挖掘中有广泛的应用，例如电子商务网络中的异常检测、社交网络中的社交推荐和基因表达分析。
* **GPU并行计算：** 论文受到GPU大规模并行计算能力的启发。然而，论文也指出，现有的MBE算法在GPU上仍面临内存需求大、线程发散和负载不平衡等挑战。GMBE+的设计正是为了克服这些挑战。
* **图表示法（Graph Representations）：** 论文对比了邻接列表和位图两种图表示法，并指出邻接列表内存效率高但集合交集耗时，而位图可以实现快速的集合交集但需要大量内存。GMBE+的位图方法借鉴了位图表示的优势，但通过在特定条件下使用来平衡内存和性能。

#### 不足或后续研究方向 (Shortcomings or Future Research Directions)
* **参数调优：** 论文的实验部分提到了为位图阈值、任务调度阈值和每个SM的warp数设置了默认值。这些值是根据经验性实验结果选择的，未来可以研究更自动化的参数选择方法来适应不同的数据集和GPU架构。
* **特定场景下的性能：** 尽管GMBE+在大多数情况下优于其变体，但在某些负载均衡良好的数据集（如Wikipedia）上，其任务调度框架由于引入了额外的开销而表现稍差。这表明在某些特定情况下，其优化策略可能不总是最优的。
* **位图开销：** 论文指出，在某些数据集（如MovieLens、Amazon、StackOverflow和IMDB）上，基于位图的集合交集方法由于创建多个位图的开销，导致性能略低于禁用该优化的变体。
* **未提及的扩展性：** 论文主要关注单机GPU上的MBE，并未讨论该方法在多GPU或分布式系统上的扩展性。
### 读后感
了解过里面提及的位图后，我发现我在Matlab公选课作业里面也曾经用过位图结构表示电路的图。在读完这篇论文后，理解了《Unix编程艺术》中提到的一点：在优化上，数据结构比算法更为重要。

## 阅读论文arXiv:1910.02054
### AI总结
#### 创新点

ZeRO 的核心创新在于**重新思考了数据并行（Data Parallelism）的内存冗余问题**，并提出了一种渐进式的解决方案，将原本在每个设备上都复制一份的模型状态（model states）进行分片（sharding）。

* **分片式数据并行（Sharded Data Parallelism）**：传统的单机数据并行会在每个 GPU 上复制一份完整的模型参数、梯度和优化器状态。ZeRO 的核心思想是，既然每个 GPU 都是用来处理一小部分数据，那么为什么不让每个 GPU 也只负责一小部分模型状态呢？它将这三种状态（参数、梯度、优化器状态）分别进行分片，并只在需要时通过高效的通信操作进行同步。
* **三阶段优化**：ZeRO 将其内存优化分为三个渐进的阶段，每个阶段都提供了额外的内存节省：
    * **ZeRO-1（Stage 1）**：只对**优化器状态**进行分片。这能显著减少内存占用，因为优化器状态（如 Adam 优化器的动量和方差）通常占据了最多的内存。
    * **ZeRO-2（Stage 2）**：在 ZeRO-1 的基础上，进一步对**梯度**进行分片。这意味着每个 GPU 只负责计算并存储其自己分到的那部分参数的梯度。
    * **ZeRO-3（Stage 3）**：在 ZeRO-2 的基础上，最激进地对**模型参数**本身也进行分片。这是最强大的优化，能将总内存占用量与设备数量成线性比例减少，使训练万亿参数级别的模型成为可能。
* **兼顾效率与通信**：ZeRO 的一个关键优势是它能够在显著减少内存消耗的同时，保持与传统数据并行相近的通信效率。它通过巧妙地将通信（如 all-reduce）与计算进行重叠（overlap），从而最大限度地掩盖通信开销，避免了模型并行中常见的高延迟和低效率问题。

---

#### 数学基础与启发

这篇论文的数学基础主要围绕**内存消耗分析**和**通信成本模型**。

* **内存消耗模型**：论文详细分析了在不同并行策略下（数据并行、模型并行等），训练一个 $P$ 参数量的模型所需的内存。它指出，对于一个使用 Adam 优化器进行 16 位混合精度训练的模型，每个设备所需的内存约为 $12P$ 字节。ZeRO 提出的分片策略，则将这一数值按分片数 $N$ 降至 $12P/N$，极大地提高了内存利用率。
* **通信成本模型**：论文在数学上比较了 ZeRO 的通信开销与传统的 all-reduce 操作。它证明了 ZeRO 的通信量与梯度和优化器状态的分片操作（如 reduce-scatter 和 all-gather）相关，并且可以被高效地实现。这使得 ZeRO 能够在大规模集群上实现“超线性”加速，因为更高的设备数量允许更大的批处理大小，从而提高了计算效率。

ZeRO 的核心思想来自于对分布式训练中“冗余”的深刻洞察：**在数据并行中，每个设备都重复存储了大量的状态信息，而这些信息在反向传播和优化器更新过程中并非总是需要全局可用的**。ZeRO 通过只在必要时“物化”（re-materialize）所需的状态，实现了内存的按需分配和高效利用。

---

#### 不足与后续研究方向

尽管 ZeRO 取得了巨大成功，但该论文也为未来的研究留下了挑战和方向。

* **ZeRO-3 的通信开销**：虽然 ZeRO-3 在内存上最为高效，但由于需要频繁地在设备间进行参数的 all-gather 和 reduce-scatter 操作，其通信开销也相对较高。在通信带宽有限的集群上，这可能会成为性能瓶颈。
* **激活（Activation）内存问题**：ZeRO 主要解决了模型状态（参数、梯度、优化器状态）的内存问题，但模型训练过程中另一个重要的内存消耗来源是激活（Activations）。为了在反向传播中使用，激活需要被保存在内存中。ZeRO-R（ZeRO-Recompute）作为后续研究方向，旨在通过激活分片和检查点技术来进一步解决这一问题。
* **与模型并行（Model Parallelism）的结合**：论文中也提到了 ZeRO 可以与模型并行（例如 Megatron-LM）结合使用，以应对那些单卡也无法加载一层模型的超巨型模型。然而，如何优雅、高效地结合这两种并行范式，仍然是一个复杂的系统工程问题。
* **通用性和易用性**：尽管 DeepSpeed 极大地简化了 ZeRO 的使用，但对于不熟悉分布式训练的开发者来说，理解和配置 ZeRO-2 或 ZeRO-3 的不同阶段以及相关的参数仍有一定门槛。后续工作将致力于进一步提高其易用性，并使其成为更多框架（如 PyTorch FSDP）的底层基础。
### 读后感
相对于流水线并行或者张量并行，ZeRO的IO瓶颈应该比较大。
